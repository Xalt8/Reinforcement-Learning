{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: keras-rl2 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: tensorflow>=2.1.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from keras-rl2) (2.3.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (0.35.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (1.33.2)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (1.18.5)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (0.11.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (1.12.1)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (0.3.3)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (2.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (3.14.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorflow>=2.1.0->keras-rl2) (1.6.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (2.25.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (1.23.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (50.3.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (3.3.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (1.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (3.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (4.6)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\singh\\onedrive\\msc_in_ai\\python\\reinforcement_learning\\env\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1.0->keras-rl2) (3.4.0)\n",
      "ERROR: unknown command \"insall\" - maybe you meant \"install\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! pip install keras-rl2\n",
    "! pip insall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "ENV_NAME = 'CartPole-v0'\n",
    "env = gym.make(ENV_NAME)\n",
    "nb_actions = env.action_space.n\n",
    "print(env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 4)                 0         \n_________________________________________________________________\ndense (Dense)                (None, 16)                80        \n_________________________________________________________________\nactivation (Activation)      (None, 16)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 16)                272       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 16)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 34        \n_________________________________________________________________\nactivation_2 (Activation)    (None, 2)                 0         \n=================================================================\nTotal params: 386\nTrainable params: 386\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training for 10000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "WARNING:tensorflow:From c:\\Users\\singh\\OneDrive\\MSc_in_AI\\Python\\Reinforcement_Learning\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "10000/10000 [==============================] - 163s 16ms/step - reward: 1.0000\n",
      "done, took 162.981 seconds\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18dca9d6dc8>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10, target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=10000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing for 10 episodes ...\n",
      "Episode 1: reward: 200.000, steps: 200\n",
      "Episode 2: reward: 200.000, steps: 200\n",
      "Episode 3: reward: 200.000, steps: 200\n",
      "Episode 4: reward: 200.000, steps: 200\n",
      "Episode 5: reward: 200.000, steps: 200\n",
      "Episode 6: reward: 200.000, steps: 200\n",
      "Episode 7: reward: 200.000, steps: 200\n",
      "Episode 8: reward: 175.000, steps: 175\n",
      "Episode 9: reward: 200.000, steps: 200\n",
      "Episode 10: reward: 200.000, steps: 200\n",
      "Mean score:\n",
      "197.5\n"
     ]
    }
   ],
   "source": [
    "scores = dqn.test(env, nb_episodes=10, visualize=False)\n",
    "print('Mean score:')\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights of the model\n",
    "dqn.save_weights('dqn_CartPole_weights.h5f', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing for 1 episodes ...\n",
      "Episode 1: reward: 200.000, steps: 200\n"
     ]
    }
   ],
   "source": [
    "dqn.test(env, nb_episodes=1, visualize=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}